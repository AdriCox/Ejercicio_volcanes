{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "294d4a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68f8368d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain = pd.read_csv('https://challenges-asset-files.s3.us-east-2.amazonaws.com/data_sets/Data-Science/4+-+events/jobmadrid/dataset/jm_train.csv')\n",
    "dftest = pd.read_csv('https://challenges-asset-files.s3.us-east-2.amazonaws.com/data_sets/Data-Science/4+-+events/jobmadrid/dataset/jm_X_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406d24ae",
   "metadata": {},
   "source": [
    "Para empezar hice un RandomForest por default con los que me salió un f1_score de 77% aprox con profundidad de entre 17-19 y unas 300 hojas. Probablemente overfitteado, por lo que paso a hacer un grid search con parámetros basados en lo que se observa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231360bf",
   "metadata": {},
   "source": [
    "Además de revisar los datos, el balanceo de clases, correlaciones entre parámetros con cada clase y la matriz de confusión de un RandomForest básico, parece que hay más fallos con las clases 1 y 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "330c9444",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dftrain.target\n",
    "X = dftrain.drop('target', axis=1)\n",
    "X2 = np.array(X) #para kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03b26a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 13,\n",
       " 'max_leaf_nodes': 90,\n",
       " 'min_impurity_decrease': 0.01,\n",
       " 'n_estimators': 201,\n",
       " 'n_jobs': -1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Realizamos búsqueda de mejores parámetros para evitar overfitting\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "parametros = {'n_estimators':[201],\n",
    "              'criterion':['entropy'],\n",
    "             'max_depth':[7,9,11,13,14],\n",
    "             'n_jobs':[-1],\n",
    "              'max_leaf_nodes': range(20,100,5),\n",
    "              'min_impurity_decrease' : [0.01]\n",
    "             }\n",
    "\n",
    "grid = GridSearchCV(estimator = clf,\n",
    "                    param_grid = parametros,\n",
    "                    scoring = 'f1_macro',\n",
    "                    n_jobs = -1 )\n",
    "\n",
    "search_result = grid.fit(X,y)\n",
    "search_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93131c39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7338869643903839\n"
     ]
    }
   ],
   "source": [
    "#MODELO AVERAGE. Uso de Kfold\n",
    "\n",
    "kfoldlist = []\n",
    "y = dftrain['target']\n",
    "X2 = np.array(dftrain.drop('target', axis=1))\n",
    "kf = StratifiedKFold()\n",
    "for train_index, test_index in kf.split(X2, y):\n",
    "    X_train, X_test = X2[train_index], X2[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    average = search_result.best_estimator_\n",
    "    \n",
    "\n",
    "    m_av = search_result.best_estimator_\n",
    "    m_av = m_av.fit(X_train, y_train)\n",
    "    yhat = m_av.predict(X_test)\n",
    "    kfoldlist.append(f1_score(y_test,yhat, average='macro'))\n",
    "\n",
    "    \n",
    "m_av.fit(X2,y)\n",
    "print(sum(kfoldlist)/len(kfoldlist))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266388c9",
   "metadata": {},
   "source": [
    "Puesto que el F1_score de la gridsearch es peor que el default, y viendo que efectivamente falla más con las clases 1 y 2. Probablemente no esté overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11a01ae1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7392940139531262\n"
     ]
    }
   ],
   "source": [
    "#MODELO PONDERADO. Uso de Kfold.\n",
    "c = dftrain.copy()\n",
    "b = dftrain[dftrain['target']==2].sample(100) #Mirando los datos de clases y                                                 \n",
    "f = dftrain[dftrain['target']==1].sample(70)  #fallos decido añadir 100 de una y 70 de otra\n",
    "d = pd.concat([b,c,f], axis=0, ignore_index=True)\n",
    "\n",
    "X2 = np.array(d.drop(['target'], axis=1))\n",
    "y = d['target']\n",
    "\n",
    "kfoldlist = []\n",
    "\n",
    "for train_index, test_index in kf.split(X2, y):\n",
    "    X_train, X_test = X2[train_index], X2[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    ponderado = search_result.best_estimator_\n",
    "    \n",
    "\n",
    "    m_pond = search_result.best_estimator_\n",
    "    m_pond = m_pond.fit(X_train, y_train)\n",
    "    yhat = m_pond.predict(X_test)\n",
    "    kfoldlist.append(f1_score(y_test,yhat, average='macro'))\n",
    "    \n",
    "m_pond.fit(X2,y)    \n",
    "print(sum(kfoldlist)/len(kfoldlist))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346b522e",
   "metadata": {},
   "source": [
    "Hago un pequeño oversampling de las clases minoritarias con idea de ponderar un tercer modelo (basándome en los dos anteriores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20a88259",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adri/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:438: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/adri/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:438: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 3, 2, 0, 3, 2, 4, 0, 2, 3, 2, 4, 3, 1, 4, 4, 4, 4, 2, 0, 1, 2,\n",
       "       3, 0, 0, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 1, 0, 4, 3, 0, 4, 2, 3, 2,\n",
       "       2, 0, 1, 1, 2, 4, 4, 0, 2, 0, 4, 4, 1, 3, 3, 0, 3, 0, 1, 0, 4, 1,\n",
       "       1, 0, 2, 3, 0, 1, 4, 0, 4, 0, 0, 3, 2, 3, 4, 3, 1, 4, 1, 1, 2, 4,\n",
       "       1, 2, 2, 4, 1, 1, 0, 1, 4, 2, 1, 4, 0, 0, 0, 4, 1, 4, 4, 4, 1, 2,\n",
       "       4, 1, 3, 3, 3, 2, 3, 4, 2, 0, 0, 4, 4, 3, 3, 2, 4, 1, 3, 2, 2, 1,\n",
       "       4, 0, 0, 0, 3, 0, 2, 4, 0, 4, 3, 2, 1, 3, 4, 3, 4, 4, 3, 2, 0, 2,\n",
       "       0, 4, 1, 4, 4, 2, 0, 1, 3, 1, 1, 4, 1, 3, 4, 1, 1, 2, 4, 4, 1, 2,\n",
       "       3, 1, 3, 4, 2, 3, 0, 4, 2, 2, 0, 3, 4, 1, 1, 3, 2, 4, 0, 0, 4, 4,\n",
       "       1, 4, 0, 2, 4, 3, 2, 2, 3, 1, 1, 3, 0, 0, 2, 1, 1, 3, 4, 0, 2, 1,\n",
       "       2, 3, 2, 0, 3, 2, 0, 2, 2, 4, 0, 2, 4, 3, 4, 4, 0, 3, 3, 3, 1, 4,\n",
       "       3, 0, 2, 0, 2, 1, 2, 0, 4, 3, 1, 3, 1, 1, 0, 3, 2, 4, 2, 1, 0, 2,\n",
       "       2, 4, 2, 4, 1, 2, 1, 4, 4, 0, 3, 0, 1, 4, 2, 4, 1, 1, 2, 1, 1, 4,\n",
       "       1, 0, 2, 2, 2, 1, 0, 2, 0, 0, 4, 4, 1, 4, 0, 4, 0, 0, 4, 4, 4, 1,\n",
       "       3, 1, 3, 4, 3, 4, 0, 0, 4, 1, 4, 4, 0, 2, 1, 4, 3, 1, 2, 1, 3, 3,\n",
       "       3, 1, 4, 2, 1, 1, 1, 0, 1, 2, 2, 3, 4, 0, 1, 2, 4, 4, 2, 2, 0, 4,\n",
       "       4, 0, 1, 4, 3, 4, 4, 1, 4, 4, 3, 1, 1, 2, 2, 2, 1, 4, 3, 3, 2, 2,\n",
       "       4, 4, 0, 2, 4, 1, 4, 0, 1, 0, 4, 2, 3, 2, 2, 4, 4, 2, 2, 3, 0, 1,\n",
       "       2, 4, 1, 4, 0, 3, 1, 4, 0, 2, 0, 0, 1, 0, 1, 1, 2, 4, 4, 0, 2, 0,\n",
       "       4, 4, 4, 3, 3, 2, 4, 4, 1, 2, 2, 2, 0, 2, 3, 0, 4, 2, 4, 0, 3, 0,\n",
       "       3, 3, 4, 3, 0, 3, 2, 4, 4, 3, 2, 3, 0, 1, 4, 2, 3, 4, 2, 0, 4, 4,\n",
       "       1, 4, 1, 3, 2, 0, 2, 0, 4, 3, 1, 4, 0, 1, 1, 2, 0, 4, 1, 3, 4, 0,\n",
       "       1, 1, 1, 4, 4, 1, 1, 3, 1, 3, 4, 3, 4, 2, 3, 4, 4, 4, 2, 4, 1, 3,\n",
       "       3, 4, 1, 0, 4, 2, 0, 3, 0, 0, 3, 3, 4, 1, 0, 2, 1, 0, 3, 2, 4, 1,\n",
       "       1, 2, 3, 1, 4, 1, 3, 3, 0, 4, 1, 2, 2, 4, 2, 2, 4, 4, 0, 0, 2, 2,\n",
       "       1, 1, 4, 0, 4, 4, 3, 0, 0, 3, 3, 2, 1, 4, 3, 3, 1, 2, 3, 4, 4, 4,\n",
       "       4, 4, 1, 4, 0, 3, 2, 4, 4, 0, 3, 2, 2, 0, 2, 2, 4, 3, 2, 3, 0, 3,\n",
       "       0, 0, 3, 0, 3, 3, 1, 3, 0, 3, 0, 1, 1, 4, 0, 2, 4, 3, 2, 1, 4, 2,\n",
       "       3, 4, 0, 0, 3, 1, 0, 4, 4, 3, 0, 3, 3, 0, 0, 1, 4, 2, 4, 4, 4, 0,\n",
       "       1, 4, 0, 4, 1, 4, 2, 1, 1, 0, 3, 1, 3, 4, 0, 3, 0, 3, 1, 3, 3, 4,\n",
       "       1, 0, 4, 0, 2, 1, 1, 1, 3, 0, 1, 4, 3, 1, 2, 0, 0, 2, 3, 0, 4, 3,\n",
       "       3, 1, 2, 1, 4, 0, 4, 2, 1, 1, 2, 4, 1, 3, 3, 4, 3, 3, 3, 1, 2, 4,\n",
       "       3, 4, 3, 2, 1, 3, 4, 2, 2, 4, 1, 3, 3, 2, 0, 3, 3, 3, 1, 1, 1, 3,\n",
       "       1, 3, 1, 3, 0, 2, 2, 3, 1, 1, 3, 3, 2, 2, 2, 3, 3, 0, 2, 2, 3, 0,\n",
       "       4, 3, 1, 0, 2, 2, 4, 1, 2, 3, 1, 3, 1, 1, 4, 4, 3, 4, 4, 4, 4, 0,\n",
       "       3, 1, 1, 2, 2, 2, 2, 3, 0, 4, 4, 0, 3, 1, 3, 2, 3, 2, 0, 4, 1, 1,\n",
       "       1, 3, 4, 3, 4, 0, 4, 3, 4, 1, 4, 2, 1, 4, 2, 2, 2, 1, 4, 4, 4, 4,\n",
       "       4, 4, 0, 1, 3, 0, 1, 4, 4, 1, 0, 1, 3, 2, 0, 0, 1, 2, 3, 0, 2, 0,\n",
       "       4, 0, 1, 0, 3, 4, 3, 1, 1, 1, 3, 2, 4, 2, 4, 1, 1, 1, 1, 1, 0, 2,\n",
       "       2, 2, 4, 3, 3, 1, 4, 4, 1, 0, 1, 1, 4, 0, 2, 1, 3, 3, 2, 4, 3, 0,\n",
       "       3, 0, 0, 4, 1, 2, 4, 0, 4, 3, 3, 3, 4, 0, 2, 3, 4, 0, 3, 4])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Conjunción de los modelos\n",
    "\n",
    "yhatpremium=[] #Será la yhat de los modelos anteriores\n",
    "avhat = m_av.predict_proba(dftest)  #modelo average\n",
    "ponhat = m_pond.predict_proba(dftest)#modelo ponderado\n",
    "\n",
    "\n",
    "for av,pon in zip(avhat, ponhat):\n",
    "    clase=list(av)\n",
    "    maximo = max(av)\n",
    "    \n",
    "    if maximo > 0.6:  #Si el modelo average está muy seguro (0.6%) lo aceptamos\n",
    "        yhatpremium.append(clase.index(maximo))\n",
    "        \n",
    "    elif clase.index(maximo) in [1,2]: #en caso contrario, si iba a decidir que era de la clase 1 ó 2,\n",
    "            matrix=[]\n",
    "            for i in range(5):         #hacemos una ponderación de cada clase entre los dos modelos\n",
    "                matrix.append(av[i]*0.15+pon[i]*0.85)#donde el modelo ponderado tiene mucho más peso que el average\n",
    "            pond_max = max(matrix)\n",
    "                \n",
    "            if pond_max>0.5:         #si tiene una seguridad aceptable (0.5%) lo aceptamos como predicción\n",
    "                yhatpremium.append(matrix.index(pond_max))\n",
    "                \n",
    "            else:                     #pero si ni aún con la ponderación tiene cierta seguridad, nos decantamos por\n",
    "                yhatpremium.append(clase.index(maximo)) #el modelo original\n",
    "    else:\n",
    "        yhatpremium.append(clase.index(maximo)) #si el modelo original no iba a predecir una clase 1 ó 2 lo mantenemos.\n",
    "        \n",
    "yhat = np.array(yhatpremium)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5affdbb0",
   "metadata": {},
   "source": [
    "Tras las validaciones de f1_score, el modelo ponderado obtiene un 0.79 con muchas menos hojas que el RandomForest por default y evitando overfittings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99e3b96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
